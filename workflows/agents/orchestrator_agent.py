from __future__ import annotations

import re

from mcp_agent.config import get_settings
from mcp_agent.core.context import initialize_context
from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM

"""OrchestratorAgent â€” dynamic DAG executor for mcpâ€‘agent workflow plans
=======================================================================
This agent receives a JSON *agent_orchestration_plan* generated by
RouterAgent, builds a DAG, and executes each step by instantiating the
corresponding specialised `mcp_agent.agents.agent.Agent` subclass.

Key features
------------
* **Dynamic DAG**Â â€“ supports any topologicallyâ€‘valid plan with arbitrary
  fanâ€‘out / fanâ€‘in.
* **Artifact Store**Â â€“ `self.artifacts` dict lets steps share objects in
  memory; each artifact is also checkpointâ€‘persisted to `workspace/` so
  the run can be resumed after failure.
* **Missingâ€‘input handling**Â â€“ if a step is flagged
  `requires_user_input: true`, execution pauses and emits
  `UserInputRequired` for external UI to collect the data.
* **Retry / degrade**Â â€“ each step retries up to `max_retries` times.  If
  still failing, behaviour is configurable (`skip` | `error`).

The class works with the standard *mcpâ€‘agent*Â API: we rely on
`Agent(...).attach_llm()` and `Agent.list_tools()` under the hood.
"""

from dataclasses import dataclass, field
from pathlib import Path
import asyncio
import json
import logging
import networkx as nx
from typing import Any, Dict, List, Optional, Type

from mcp_agent.agents.agent import Agent  # base class from your codebase
from utils.json_tools import safe_json_loads  # robust JSON parser used elsewhere

logger = logging.getLogger(__name__)

DEFAULT_WORKSPACE_ROOT = Path("deepcode_lab")
def _persist(self, art_key: str, value: Any):
    fname = self.workspace / f"{art_key}.json"
    try:
        with fname.open("w", encoding="utf-8") as f:
            json.dump(value, f, ensure_ascii=False, indent=2)
    except (TypeError, PermissionError, OSError) as e:
        logger.error("ğŸ’¾ Persist error for %s â†’ %s: %s", art_key, fname, e)
        raise                    # è®©ä¸Šå±‚é‡è¯•/é™çº§
def safe_dirname(raw: str, max_len: int = 15) -> str:
    """
    å°†ä»»æ„å­—ç¬¦ä¸²è£å‰ªæˆç£ç›˜å®‰å…¨çš„ç›®å½•åï¼š
        1. æŠŠéå­—æ¯æ•°å­—æ›¿æ¢æˆä¸‹åˆ’çº¿
        2. å»æ‰é¦–å°¾ä¸‹åˆ’çº¿
        3. æˆªå–å‰ max_len ä¸ªå­—ç¬¦
    """
    slug = re.sub(r"[^A-Za-z0-9]+", "_", raw).strip("_")
    return slug[:max_len]

@dataclass
class StepSpec:
    id: str
    agent_name: str
    inputs: Dict[str, Any]
    outputs: List[str]
    depends_on: List[str] = field(default_factory=list)
    server_names: List[str] = field(default_factory=list)
    requires_user_input: bool = False
    max_retries: int = 3
    degrade_strategy: str = "error"  # or "skip"

    @staticmethod
    def from_json(obj: Dict[str, Any]) -> "StepSpec":
        return StepSpec(
            id=obj["id"],
            agent_name=obj["agent"],
            inputs=obj.get("inputs", {}),
            outputs=obj.get("outputs", []),
            depends_on=obj.get("depends_on", []),
            server_names=obj.get("server_names", []),
            requires_user_input=obj.get("requires_user_input", False),
        )
project_root = Path(__file__).resolve().parents[2]  # DeepCode-main
config_path  = project_root / "mcp_agent.config.yaml"
secrets_path = project_root / "mcp_agent.secrets.yaml"
class OrchestratorAgent:
    """Runs a plan JSON using existing specialised Agents."""

    def __init__(
        self,
        plan_json: str | Dict[str, Any],
        registry: Dict[str, Type[Agent]],
        workspace: Path | str | None = None,
    ) -> None:
        # Parse plan
        if isinstance(plan_json, str):
            plan = safe_json_loads(plan_json)
        else:
            plan = plan_json

        if plan.get("plan_type") != "agent_orchestration_plan":
            raise ValueError("unsupported plan_type")

        self.global_context = plan.get("global_context", {})
        self.steps: Dict[str, StepSpec] = {
            s["id"]: StepSpec.from_json(s) for s in plan["steps"]
        }
        self.registry = registry
        self.artifacts: Dict[str, Any] = {}
        self.llm = OpenAIAugmentedLLM(
            model="deepseek-chat",
            config_path=secrets_path
        )
        self.workspace = Path(workspace) if workspace else DEFAULT_WORKSPACE_ROOT / Path(
            safe_dirname(self.global_context.get("goal", "generic_task"))
        )
        self.workspace.mkdir(parents=True, exist_ok=True)

        self._build_graph()

        self._config_path = "mcp_agent.config.yaml"
        self._context = None
            # ------------------------------------------------------------------
    # DAG helpers
    # ------------------------------------------------------------------
    def _build_graph(self):
        self.G = nx.DiGraph()
        for sid, spec in self.steps.items():
            self.G.add_node(sid)
            for dep in spec.depends_on:
                self.G.add_edge(dep, sid)
        if not nx.is_directed_acyclic_graph(self.G):
            raise ValueError("Plan has cyclic dependencies")

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    async def run_async(self):

        # åœ¨è¿™é‡Œåˆå§‹åŒ– Contextï¼ˆæ‹¿åˆ° settings åï¼‰
        if self._context is None:
            self._context = await initialize_context(
                config=get_settings(self._config_path),
                store_globally=True  # æˆ– Falseï¼ŒäºŒé€‰ä¸€ï¼›æœ‰å…¨å±€è¯»å–éœ€æ±‚å¯è®¾ True
                )

            # å‡†å¤‡ä¸€ä¸ª llm_factoryï¼ˆä»¥ DeepSeek OpenAI å…¼å®¹ä¸ºä¾‹ï¼‰
        self._llm_factory = lambda agent: OpenAIAugmentedLLM(
            agent=agent,
            context=self._context,
            model="deepseek-chat"
        )
        #"""Execute the DAG asynchronously."""
        # queue of ready step ids
        ready = [n for n in self.G.nodes if self.G.in_degree(n) == 0]
        in_progress: set[str] = set()
        completed: set[str] = set()

        while ready or in_progress:
            # schedule ready steps in parallel
            tasks = {}
            for sid in ready:
                in_progress.add(sid)
                tasks[sid] = asyncio.create_task(self._run_step(self.steps[sid]))
            ready.clear()

            # wait for first finished task
            done, _ = await asyncio.wait(tasks.values(), return_when=asyncio.FIRST_COMPLETED)
            for t in done:
                sid, success = t.result()  # each task returns (sid, success)
                in_progress.discard(sid)
                if success:
                    completed.add(sid)
                    # push children whose deps are all completed
                    for child in self.G.successors(sid):
                        if child in completed or child in in_progress:
                            continue
                        if all(pred in completed for pred in self.steps[child].depends_on):
                            ready.append(child)
                else:
                    logger.error("Step %s failed irrecoverably", sid)
                    if self.steps[sid].degrade_strategy == "error":
                        raise RuntimeError(f"Workflow halted due to step {sid} failure")
                    # skip strategy: mark as completed with None outputs
                    completed.add(sid)

        logger.info("Workflow completed âœ…")

    # ------------------------------------------------------------------
    # Step executor
    # ------------------------------------------------------------------
    async def _run_step(self, spec: StepSpec) -> tuple[str, bool]:
        """Execute a single step. Return (step_id, success_flag)."""
        logger.info("â–¶ï¸  Step %s (%s)", spec.id, spec.agent_name)
        entry = self.registry.get(spec.agent_name)
        if entry is None:
            logger.error("Unknown agent: %s", spec.agent_name)
            return spec.id, False
        elif isinstance(entry,Agent):
            agent_cls =entry
        elif isinstance(entry, type) and issubclass(entry, Agent):
            async with entry(
                    name=spec.id,
                    instruction="",
                    server_names=spec.server_names,
            ) as agent_cls:
                pass# Resolve inputs
        try:
            inputs = {k: self._resolve(v) for k, v in spec.inputs.items()}
        except KeyError as e:
            if spec.requires_user_input:
                logger.warning("Step %s requires user input: %s", spec.id, e)
                raise UserInputRequired(f"Step {spec.id} missing input {e}")
            else:
                logger.error("Missing input %s for step %s", e, spec.id)
                return spec.id, False

        # retry loop
        for attempt in range(1, spec.max_retries + 1):
            try:
                #è¿™é‡Œå‡ºé”™
                llm = await agent_cls.attach_llm(llm_factory=self._llm_factory)

                # 1) ç»„è£… messagesï¼ˆä¼˜å…ˆç”¨ä½  step ä¼ æ¥çš„ messagesï¼›å¦åˆ™ç”¨ promptï¼›å†å¦åˆ™æŠŠ inputs ä¸²æˆä¸€æ®µï¼‰
                if "messages" in inputs and isinstance(inputs["messages"], list):
                    messages = inputs["messages"]
                else:
                    user_text = inputs.get("prompt") or json.dumps(inputs, ensure_ascii=False)
                    messages = [
                        {"role": "system",
                         "content": getattr(agent_cls, "instruction", "") or "You are a helpful agent."},
                        {"role": "user", "content": user_text},
                    ]

                # 2) è°ƒ LLM
                out_messages = await llm.generate(messages)
                # 3) æŠŠæ¨¡å‹è¾“å‡ºè½¬æˆçº¯æ–‡æœ¬ï¼ˆå…¼å®¹ pydantic/dict ä¸¤ç§å½¢æ€ï¼‰
                texts = []
                for m in out_messages:
                    role = getattr(m, "role", None) if not isinstance(m, dict) else m.get("role")
                    if role == "assistant":
                        content = getattr(m, "content", None) if not isinstance(m, dict) else m.get("content")
                        if isinstance(content, str):
                            texts.append(content)
                        elif isinstance(content, list):
                            parts = []
                            for c in content:
                                typ = getattr(c, "type", None) if not isinstance(c, dict) else c.get("type")
                                if typ == "text":
                                    parts.append(
                                        getattr(c, "text", "") if not isinstance(c, dict) else c.get("text", ""))
                            texts.append("\n".join(p for p in parts if p))
                        else:
                            # å…œåº•
                            try:
                                texts.append(m.model_dump().get("content", ""))  # pydantic v2
                            except Exception:
                                texts.append(str(content))

                # texts å°±æ˜¯è¿™ä¸€æ­¥çš„â€œç»“æœæ–‡æœ¬â€
                result = "\n".join(t for t in texts if t)

                if not isinstance(result, (list, tuple)):
                    result = [result]
                # map outputs
                for name, val in zip(spec.outputs, result):
                    art_key = f"{spec.id}.{name}"
                    self.artifacts[art_key] = val
                    self._persist(art_key, val)
                logger.info("âœ…  Step %s succeeded", spec.id)
                return spec.id, True
            except Exception as e:
                logger.warning("Attempt %d/%d failed for step %s: %s", attempt, spec.max_retries, spec.id, e)
                await asyncio.sleep(2 ** (attempt - 1))
        logger.error("âŒ  Step %s failed after %d retries", spec.id, spec.max_retries)
        return spec.id, False

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _resolve(self, val):
        """Resolve artifact reference like 'step.output' into actual object."""
        if isinstance(val, str) and val.count(".") == 1:
            step_id, key = val.split(".")
            art_key = f"{step_id}.{key}"
            if art_key in self.artifacts:
                return self.artifacts[art_key]
        return val

    def _persist(self, art_key: str, value: Any):
        """Persist artifact as JSON if possible, fallback to pickle."""
        fname = self.workspace / f"{art_key}.json"
        try:
            with fname.open("w", encoding="utf-8") as f:
                json.dump(value, f, ensure_ascii=False, indent=2)
        except TypeError:
            import pickle, gzip
            fname = self.workspace / f"{art_key}.pkl.gz"
            with gzip.open(fname, "wb") as f:
                pickle.dump(value, f)

# ----------------- Example Usage ------------------------------------
if __name__ == "__main__":
    import asyncio
    from workflows.agents.registry import registry  # your code should provide this mapping
    #éœ€è¦æ³¨å†Œè¡¨
    with open("D:\PythonProjects\DeepCode-main/1.txt", "r", encoding="utf-8") as f:
        PLAN_JSON = json.load(f)

    orch = OrchestratorAgent(PLAN_JSON, registry)
    asyncio.run(orch.run_async())
